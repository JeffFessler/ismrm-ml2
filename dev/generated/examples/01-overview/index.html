<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>01-overview · ismrm_ml2</title><meta name="title" content="01-overview · ismrm_ml2"/><meta property="og:title" content="01-overview · ismrm_ml2"/><meta property="twitter:title" content="01-overview · ismrm_ml2"/><meta name="description" content="Documentation for ismrm_ml2."/><meta property="og:description" content="Documentation for ismrm_ml2."/><meta property="twitter:description" content="Documentation for ismrm_ml2."/><meta property="og:url" content="https://JeffFessler.github.io/ismrm_ml2.jl/stable/generated/examples/01-overview/"/><meta property="twitter:url" content="https://JeffFessler.github.io/ismrm_ml2.jl/stable/generated/examples/01-overview/"/><link rel="canonical" href="https://JeffFessler.github.io/ismrm_ml2.jl/stable/generated/examples/01-overview/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">ismrm_ml2</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>01-overview</a><ul class="internal"><li><a class="tocitem" href="#Basic-Introduction-to-Machine-Learning:-01-overview"><span>Basic Introduction to Machine Learning: 01-overview</span></a></li><li><a class="tocitem" href="#Supervised-learning:-classification"><span>Supervised learning: classification</span></a></li><li><a class="tocitem" href="#Supervised-learning:-regression"><span>Supervised learning: regression</span></a></li><li><a class="tocitem" href="#Unsupervised-learning:-data"><span>Unsupervised learning: data</span></a></li><li><a class="tocitem" href="#Clustering-(oracle)"><span>Clustering (oracle)</span></a></li><li><a class="tocitem" href="#Novelty-detection"><span>Novelty detection</span></a></li><li><a class="tocitem" href="#2D-example"><span>2D example</span></a></li><li><a class="tocitem" href="#Nonlinear-lifting-into-3D"><span>Nonlinear lifting into 3D</span></a></li><li><a class="tocitem" href="#Nonlinearity-in-regression"><span>Nonlinearity in regression</span></a></li><li><a class="tocitem" href="#Linear-discriminant-analysis-(LDA)"><span>Linear discriminant analysis (LDA)</span></a></li><li><a class="tocitem" href="#Cross-validation"><span>Cross-validation</span></a></li></ul></li><li><a class="tocitem" href="../02-digits/">02-digits</a></li><li><a class="tocitem" href="../03-flux-ring2/">03-flux-ring2</a></li><li><a class="tocitem" href="../04-denoise-1d/">04-denoise-1d</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>01-overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>01-overview</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JeffFessler/ismrm_ml2" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JeffFessler/ismrm_ml2/blob/main/docs/lit/examples/01-overview.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="01-overview"><a class="docs-heading-anchor" href="#01-overview">01-overview</a><a id="01-overview-1"></a><a class="docs-heading-anchor-permalink" href="#01-overview" title="Permalink"></a></h1><h2 id="Basic-Introduction-to-Machine-Learning:-01-overview"><a class="docs-heading-anchor" href="#Basic-Introduction-to-Machine-Learning:-01-overview">Basic Introduction to Machine Learning: 01-overview</a><a id="Basic-Introduction-to-Machine-Learning:-01-overview-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Introduction-to-Machine-Learning:-01-overview" title="Permalink"></a></h2><p>This page was generated from a single Julia file: <a href="https://github.com/JeffFessler/ismrm_ml2/blob/main/docs/lit/examples/01-overview.jl">01-overview.jl</a>.</p><p>In any such Julia documentation, you can access the source code using the &quot;Edit on GitHub&quot; link in the top right.</p><p>The corresponding notebook can be viewed in <a href="https://nbviewer.org/">nbviewer</a> here: <a href="https://nbviewer.org/github/JeffFessler/ismrm_ml2/tree/gh-pages/dev/generated/examples/01-overview.ipynb"><code>01-overview.ipynb</code></a>, and opened in <a href="https://mybinder.org/">binder</a> here: <a href="https://mybinder.org/v2/gh/JeffFessler/ismrm_ml2/gh-pages?filepath=dev/generated/examples/01-overview.ipynb"><code>01-overview.ipynb</code></a>.</p><h3 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h3><p>Packages needed here.</p><pre><code class="language-julia hljs">using LinearAlgebra: norm
using Random: seed!
using LaTeXStrings # pretty plot labels
using Plots: plot, plot!, scatter, scatter!, surface!, default, font, gui
using MIRTjim: jim, prompt
using InteractiveUtils: versioninfo

default(markersize=5, markerstrokecolor=:auto, label=&quot;&quot;)
fnt = font(&quot;DejaVu Sans&quot;, 15) # larger default font
default(guidefont=fnt, xtickfont=fnt, ytickfont=fnt, legendfont=fnt)
default(tickfontsize=10, legendfontsize=11)</code></pre><p>The following line is helpful when running this file as a script; this way it will prompt user to hit a key after each figure is displayed.</p><pre><code class="language-julia hljs">isinteractive() ? jim(:prompt, true) : prompt(:draw);</code></pre><h2 id="Supervised-learning:-classification"><a class="docs-heading-anchor" href="#Supervised-learning:-classification">Supervised learning: classification</a><a id="Supervised-learning:-classification-1"></a><a class="docs-heading-anchor-permalink" href="#Supervised-learning:-classification" title="Permalink"></a></h2><pre><code class="language-julia hljs">seed!(0)
n1 = 50; n2 = n1
rot = phi -&gt; [cos(phi) sin(-phi); sin(phi) cos(phi)]
data1 = rot(π/8) * ([3 0; 0 1] * randn(2,n1) .+ [8;2])
data2 = rot(π/4) * ([2 0; 0 1] * randn(2,n2) .+ [9;3])
scatter(data1[1,:], data1[2,:], color=:blue, label=&quot;class1&quot;)
scatter!(data2[1,:], data2[2,:], color=:red, label=&quot;class2&quot;)
plot!(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;)
plot!(xlim=(0,14), ylim=(0,14))
plot!(aspect_ratio=1, xtick=[0, 14], ytick=[0, 14])
x = LinRange(0,14,101)
y = 2 .+ x - 0.03 * x.^2 # add decision boundary
plot!(x, y, color=:magenta)</code></pre><img src="ec97b989.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Supervised-learning:-regression"><a class="docs-heading-anchor" href="#Supervised-learning:-regression">Supervised learning: regression</a><a id="Supervised-learning:-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Supervised-learning:-regression" title="Permalink"></a></h2><pre><code class="language-julia hljs">seed!(0)
N = 40
f = (x) -&gt; 10. / (x + 1)
xt = 10 * rand(N)
yt = f.(xt) + 0.4 * randn(N)
x = range(0, 10, 101)
y = f.(x)
scatter(xt, yt, color=:blue, label=&quot;training data&quot;)
plot!(xlabel=L&quot;x&quot;, ylabel=L&quot;y&quot;)
plot!(xlim=(0,10), ylim=(0,8))
plot!(xtick=0:5:10, ytick=0:4:8)</code></pre><img src="c3c578b0.svg" alt="Example block output"/><p>Polynomial regression model</p><pre><code class="language-julia hljs">Afun = (tt) -&gt; [t.^i for t in tt, i in 0:3] # matrix of monomials
A = Afun(xt)
coef = A \ yt
y = Afun(x) * coef
plot!(x, y, line=:magenta, label=&quot;cubic regression&quot;)</code></pre><img src="6c09dad3.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Unsupervised-learning:-data"><a class="docs-heading-anchor" href="#Unsupervised-learning:-data">Unsupervised learning: data</a><a id="Unsupervised-learning:-data-1"></a><a class="docs-heading-anchor-permalink" href="#Unsupervised-learning:-data" title="Permalink"></a></h2><pre><code class="language-julia hljs">seed!(0)
n1 = 50; n2 = n1; n3=n1
rot = phi -&gt; [cos(phi) sin(-phi); sin(phi) cos(phi)]
data1 = rot(π/4) * ([2 0; 0 0.7] * randn(2,n1) .+ [9;3])
data2 = rot(π/8) * ([3 0; 0 0.6] * randn(2,n2) .+ [8;2])
data3 = rot( 0 ) * ([2 0; 0 0.5] * randn(2,n3) .+ [9;1]);

plot(xlabel = L&quot;x_1&quot;, ylabel = L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:black, label=&quot;training data&quot;)
scatter!(data2[1,:], data2[2,:], color=:black)
scatter!(data3[1,:], data3[2,:], color=:black)
plot!(xlim=(0,14), ylim=(0,14))
plot!(aspect_ratio=1, xtick=[0, 14], ytick=[0, 14])</code></pre><img src="e5ffee7f.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Clustering-(oracle)"><a class="docs-heading-anchor" href="#Clustering-(oracle)">Clustering (oracle)</a><a id="Clustering-(oracle)-1"></a><a class="docs-heading-anchor-permalink" href="#Clustering-(oracle)" title="Permalink"></a></h2><pre><code class="language-julia hljs">plot(xlabel = L&quot;x_1&quot;, ylabel = L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:blue, label=&quot;cluster1&quot;)
scatter!(data2[1,:], data2[2,:], color=:red, label=&quot;cluster2&quot;)
scatter!(data3[1,:], data3[2,:], color=:orange, label=&quot;cluster3&quot;)
plot!(xlim=(0,14), ylim=(0,14))
plot!(aspect_ratio=1, xtick=[0, 14], ytick=[0, 14])</code></pre><img src="c35776fa.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Novelty-detection"><a class="docs-heading-anchor" href="#Novelty-detection">Novelty detection</a><a id="Novelty-detection-1"></a><a class="docs-heading-anchor-permalink" href="#Novelty-detection" title="Permalink"></a></h2><pre><code class="language-julia hljs">plot(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:black)
scatter!(data2[1,:], data2[2,:], color=:black)
scatter!(data3[1,:], data3[2,:], color=:black)
scatter!([10], [11], color=:red)
plot!(xlim=(0,14), ylim=(0,14))
plot!(aspect_ratio=1, xtick=[0, 14], ytick=[0, 14])</code></pre><img src="5785c558.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h3 id="The-utility-of-nonlinearity"><a class="docs-heading-anchor" href="#The-utility-of-nonlinearity">The utility of nonlinearity</a><a id="The-utility-of-nonlinearity-1"></a><a class="docs-heading-anchor-permalink" href="#The-utility-of-nonlinearity" title="Permalink"></a></h3><p>1D plot supervised learning: classification</p><pre><code class="language-julia hljs">seed!(0)
n1 = 20; n2 = n1; n3 = n1
data1 = 1 * randn(2,n1) .+ 5
data2 = 1 * randn(2,n2) .+ 0
data3 = 1 * randn(2,n3) .+ (-5)
plot(xlabel=L&quot;x_1&quot;, ylabel=&quot;&quot;)
scatter!(data1[1,:], zeros(n1), color=:blue, label=&quot;class1&quot;)
scatter!(data2[1,:], zeros(n2), color=:red, label=&quot;class2&quot;)
scatter!(data3[1,:], zeros(n3), color=:blue)
plot!(xlim=(-8,7), ylim=(-1,1))
plot!(xtick=-6:3:6, ytick=[])
plot!([1, 1]*2, [-1, 1], color=:orange)</code></pre><img src="22daada0.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>A simple nonlinearity, abs(feature), allows linear separation</p><pre><code class="language-julia hljs">f = x -&gt; abs(x)
data1[2,:] = f.(data1[1,:])
data2[2,:] = f.(data2[1,:])
data3[2,:] = f.(data3[1,:])
plot(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:blue, label=&quot;class1&quot;)
scatter!(data2[1,:], data2[2,:], color=:red, label=&quot;class2&quot;)
scatter!(data3[1,:], data3[2,:], color=:blue)
plot!(xlim=(-8,7), ylim=(-1,10))
plot!(xtick=-6:3:6, ytick=0:5:10)
plot!([-1, 1]*8, [1, 1]*2.4, color=:orange, width=2, legend=:top)</code></pre><img src="d552dd82.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="2D-example"><a class="docs-heading-anchor" href="#2D-example">2D example</a><a id="2D-example-1"></a><a class="docs-heading-anchor-permalink" href="#2D-example" title="Permalink"></a></h2><pre><code class="language-julia hljs">seed!(0)
n1 = 40; n2 = 120
data1 = randn(2,n1)
rad2 = 3 .+ 3*rand(1,n2)
ang2 = rand(1,n2) * 2π
data2 = [rad2 .* cos.(ang2); rad2 .* sin.(ang2)]
plot(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:blue, label=&quot;class1&quot;)
scatter!(data2[1,:], data2[2,:], color=:red, label=&quot;class2&quot;)
plot!(xlim=[-1,1]*6, ylim=[-1,1]*6)
plot!(aspect_ratio=1, xtick=-6:6:6, ytick=-6:6:6)</code></pre><img src="390f07e3.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()

plot!([0, 1, 0, -1, 0]*3, [-1, 0, 1, 0, -1]*3, color=:orange, width=2)</code></pre><img src="e3495bec.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Nonlinear-lifting-into-3D"><a class="docs-heading-anchor" href="#Nonlinear-lifting-into-3D">Nonlinear lifting into 3D</a><a id="Nonlinear-lifting-into-3D-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-lifting-into-3D" title="Permalink"></a></h2><pre><code class="language-julia hljs">lift_fun = (x) -&gt; sum(abs.(x), dims=1)
lift1 = [data1; lift_fun(data1)]
lift2 = [data2; lift_fun(data2)]
plot(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;, zlabel=L&quot;$x_3 = |x_1| + |x_2|$&quot;)
scatter!(lift1[1,:], lift1[2,:], lift1[3,:], color=:blue, label=&quot;class1&quot;)
scatter!(lift2[1,:], lift2[2,:], lift2[3,:], color=:red, label=&quot;class2&quot;)
plot!(xlim=[-1,1]*6, ylim=[-1,1]*6)
plot!(xtick=-6:6:6, ytick=-6:6:6)
plot!(camera=(30,12))
#savefig(&quot;ml-nonlin2d-lift.pdf&quot;)</code></pre><img src="7f475c30.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()


xc = -6:6
yc = -6:6
z = 3 * ones(length(xc), length(yc)) # 3 chosen manually
surface!(xc, yc, z, colorbar=nothing, alpha=0.6) #, color=:orange)</code></pre><img src="fe815f70.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Nonlinearity-in-regression"><a class="docs-heading-anchor" href="#Nonlinearity-in-regression">Nonlinearity in regression</a><a id="Nonlinearity-in-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinearity-in-regression" title="Permalink"></a></h2><pre><code class="language-julia hljs">seed!(0)
N = 40
f = (x) -&gt; 10. / (x + 1)
xt = 10 * rand(N)
yt = f.(xt) + 0.4 * randn(N)
x = range(0, 10, 101)
y = f.(x)
scatter(xt, yt, color=:blue, label=&quot;training data for regression&quot;)
plot!(xlabel=L&quot;x&quot;, ylabel=L&quot;y&quot;)
plot!(xlim=(0,10), ylim=(0,8))
plot!(xtick=0:5:10, ytick=0:4:8)

Afun = (tt,deg) -&gt; [t.^i for t in tt, i in 0:deg] # matrix of monomials
A3 = Afun(xt,3)
coef3 = A3 \ yt
y3 = Afun(x,3) * coef3;

A1 = Afun(xt,1)
coef1 = A1 \ yt
y1 = Afun(x,1) * coef1;

plot!(x, y3, line=:magenta,
    label = L&quot;\mathrm{cubic:\ } y = \alpha_3 x^3 + \alpha_2 x^2 + \alpha_1 x + \alpha_0&quot;)
plot!(x, y1, line=(:dash,:red),
    label = L&quot;\mathrm{linear\ (affine):\ } y = \alpha_1 x + \alpha_0&quot;)</code></pre><img src="a458692e.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Linear-discriminant-analysis-(LDA)"><a class="docs-heading-anchor" href="#Linear-discriminant-analysis-(LDA)">Linear discriminant analysis (LDA)</a><a id="Linear-discriminant-analysis-(LDA)-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-discriminant-analysis-(LDA)" title="Permalink"></a></h2><p><a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">LDA</a></p><pre><code class="language-julia hljs">seed!(0)
n1 = 70; n2 = n1
rot = phi -&gt; [cos(phi) sin(-phi); sin(phi) cos(phi)]
mu1 = [7, 10]
mu2 = [9, 4]
S1 = rot(π/9) * [3 0; 0 1]
S2 = S1 # for LDA
data1 = S1 * randn(2,n1) .+ mu1
data2 = S2 * randn(2,n2) .+ mu2
plot(xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;)
scatter!(data1[1,:], data1[2,:], color=:blue, label=&quot;class1&quot;)
scatter!(data2[1,:], data2[2,:], color=:red, label=&quot;class2&quot;)
plot!(xlim=(0,16), ylim=(0,16))
plot!(aspect_ratio=1)
plot!(xtick=0:4:16, ytick=0:4:16)

ϕ = range(0,2π,101)
for r in [1.5 2.5]
    local x = r * cos.(ϕ)
    local y = r * sin.(ϕ)
    c1 = S1 * [x&#39;; y&#39;] .+ mu1
    c2 = S2 * [x&#39;; y&#39;] .+ mu2
    plot!(c1[1,:], c1[2,:], color=:blue)
    plot!(c2[1,:], c2[2,:], color=:red)
end
x = range(-1,17,11)
w = (S1 * S1&#39;) \ (mu2 - mu1) # LDA
c = (norm(S1 \ mu2)^2 - norm(S1 \ mu1)^2)/2
y = (c .- w[1] * x) / (w[2])
plot!(x, y, color=:magenta, width=2, legend=:topleft)</code></pre><img src="37fd4753.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h3 id="Model-order-selection"><a class="docs-heading-anchor" href="#Model-order-selection">Model-order selection</a><a id="Model-order-selection-1"></a><a class="docs-heading-anchor-permalink" href="#Model-order-selection" title="Permalink"></a></h3><p>Sinusoidal regression training data</p><pre><code class="language-julia hljs">seed!(0)
Ntrain = 40
Ntest = 30
f = (x) -&gt; 10. / (x + 1)
xtrain = 10 * rand(Ntrain)
ytrain = f.(xtrain) + 0.4 * randn(Ntrain)
xtest = 10 * rand(Ntest)
ytest = f.(xtest) + 0.4 * randn(Ntest)

x = range(0,10,201)
y = f.(x)

plot(xlabel=L&quot;x&quot;, ylabel=L&quot;y&quot;)
scatter!(xtrain, ytrain, color=:blue, label=&quot;training data&quot;)
scatter!(xtest, ytest, color=:red, label=&quot;test data&quot;)
plot!(xlim=(0,10), ylim=(0,8))
plot!(xtick=0:5:10, ytick=0:4:8)</code></pre><img src="eb9cff50.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>Show overfit</p><pre><code class="language-julia hljs">scatter(xtrain, ytrain, color=:blue, label=&quot;training data&quot;)
plot!(xlim=(0,10), ylim=(0,8))
plot!(xtick=0:5:10, ytick=0:4:8)

Afun = (tt,deg) -&gt; [t.^i for t in tt, i in 0:deg] # matrix of monomials
Afun = (tt,deg) -&gt; [cos(2π*t*i/20) for t in tt, i in 0:deg] # matrix of sinusoids
dlist = [2 9 20]
clist = (:magenta, :red, :orange)
for ii in 1:length(dlist)
    local deg = dlist[ii]
    local A = Afun(xtrain,deg)
    local coef = A \ ytrain
    local y = Afun(x,deg) * coef
    plot!(x, y, line=clist[ii], width=2, label=&quot;$deg harmonics&quot;)
end
plot!(xlabel=L&quot;x&quot;, ylabel=L&quot;y&quot;)</code></pre><img src="cc4b666f.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>Fit improves with more harmonics, of course</p><pre><code class="language-julia hljs">dlist = 0:30
etrain = zeros(length(dlist))
etest = zeros(length(dlist))
errs = zeros(length(dlist))
for ii in 1:length(dlist)
    deg = dlist[ii]
    Atrain = Afun(xtrain, deg)
    Atest = Afun(xtest, deg)
    # @show cond(A&#39;*A) # sinusoids is more stable than polynomials
    local coef = Atrain \ ytrain
    yh = Atrain * coef
    etrain[ii] = norm(yh - ytrain)
    etest[ii] = norm(Atest * coef - ytest)
    errs[ii] = norm(yh - f.(xt))
end
scatter(dlist, etrain, color=:blue, label=&quot;fit to training data&quot;)
plot!(xlabel = &quot;model order: # of sinusoids&quot;)
plot!(ylabel = L&quot;\mathrm{fit:\ } ‖ \hat{y} - y ‖_2&quot;)
plot!(ylim=[0,13], ytick=[0,13])
scatter!(dlist, etest, color=:red, label=&quot;fit to test data&quot;)</code></pre><img src="49c76cf9.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h2 id="Cross-validation"><a class="docs-heading-anchor" href="#Cross-validation">Cross-validation</a><a id="Cross-validation-1"></a><a class="docs-heading-anchor-permalink" href="#Cross-validation" title="Permalink"></a></h2><pre><code class="language-julia hljs">Nlearn = Int(Ntrain / 2)
Nvalid = Ntrain - Nlearn
xlearn = xtrain[1:Nlearn]
ylearn = ytrain[1:Nlearn]
xvalid = xtrain[(Nlearn+1):Ntrain]
yvalid = ytrain[(Nlearn+1):Ntrain]

plot(xlabel=L&quot;x&quot;, ylabel=L&quot;y&quot;)
scatter!(xlearn, ylearn, color=:blue, label=&quot;training data (fitting)&quot;)
scatter!(xvalid, yvalid, color=:cyan, label=&quot;validation data (model selection)&quot;)
plot!(xlim=(0,10), ylim=(0,8))
plot!(xtick=0:5:10, ytick=0:4:8)</code></pre><img src="66684ac6.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><p>fit improves with more harmonics, of course</p><pre><code class="language-julia hljs">dlist = 0:20
elearn = zeros(length(dlist))
evalid = zeros(length(dlist))
etest = zeros(length(dlist))
errs = zeros(length(dlist))
for ii in 1:length(dlist)
    deg = dlist[ii]
    Alearn = Afun(xlearn, deg)
    Avalid = Afun(xvalid, deg)
    Atest = Afun(xtest, deg)
    # @show cond(A&#39;*A) # sinusoids is more stable than polynomials
    local coef = Alearn \ ylearn
    elearn[ii] = norm(Alearn * coef - ylearn)
    evalid[ii] = norm(Avalid * coef - yvalid)
    etest[ii] = norm(Atest * coef - ytest)
    errs[ii] = norm([Alearn; Avalid]*coef - f.([xlearn; xvalid]))
end
scatter(dlist, elearn, color=:blue, label=&quot;fit to training data&quot;)
scatter!(dlist, evalid, color=:cyan, label=&quot;fit to validation data&quot;)
plot!(xlabel = &quot;model order: # of sinusoids&quot;)
plot!(ylabel = L&quot;fit: \ ‖ \hat{y} - y ‖_2&quot;)
plot!(ylim=[0,13], ytick=[0,13])
dbest = findall(diff(evalid) .&gt;= 0)[1] # find first increase in validation error
plot!(xtick=[0, dlist[dbest], 20])
scatter!(dlist, etest, color=:red, label=&quot;fit to test data&quot;)</code></pre><img src="16aa52db.svg" alt="Example block output"/><pre><code class="language-julia hljs">prompt()</code></pre><h3 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h3><p>This page was generated with the following version of Julia:</p><pre><code class="language-julia hljs">io = IOBuffer(); versioninfo(io); split(String(take!(io)), &#39;\n&#39;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">12-element Vector{SubString{String}}:
 &quot;Julia Version 1.10.0&quot;
 &quot;Commit 3120989f39b (2023-12-25 18:01 UTC)&quot;
 &quot;Build Info:&quot;
 &quot;  Official https://julialang.org/ release&quot;
 &quot;Platform Info:&quot;
 &quot;  OS: Linux (x86_64-linux-gnu)&quot;
 &quot;  CPU: 4 × AMD EPYC 7763 64-Core Processor&quot;
 &quot;  WORD_SIZE: 64&quot;
 &quot;  LIBM: libopenlibm&quot;
 &quot;  LLVM: libLLVM-15.0.7 (ORCJIT, znver3)&quot;
 &quot;  Threads: 1 on 4 virtual cores&quot;
 &quot;&quot;</code></pre><p>And with the following package versions</p><pre><code class="language-julia hljs">import Pkg; Pkg.status()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Status `~/work/ismrm_ml2/ismrm_ml2/docs/Project.toml`
  [31c24e10] Distributions v0.25.107
  [e30172f5] Documenter v1.2.1
  [587475ba] Flux v0.14.9
  [b964fa9f] LaTeXStrings v1.3.1
  [98b081ad] Literate v2.16.1
  [170b2178] MIRTjim v0.23.0
  [eb30cadb] MLDatasets v0.7.14
  [91a5bcdd] Plots v1.39.0
  [2913bbd2] StatsBase v0.34.2
  [1986cc42] Unitful v1.19.0
  [ef84fa70] ismrm_ml2 v0.0.1 `~/work/ismrm_ml2/ismrm_ml2`
  [b77e0a4c] InteractiveUtils
  [37e2e46d] LinearAlgebra
  [9a3f8284] Random</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../../">« Home</a><a class="docs-footer-nextpage" href="../02-digits/">02-digits »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Monday 22 January 2024 02:00">Monday 22 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
